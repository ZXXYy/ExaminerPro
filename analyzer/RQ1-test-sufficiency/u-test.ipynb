{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test cases 10 times using different strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "encoding = 'A64'\n",
    "arch = 'AArch32'\n",
    "strategy = 'random-symbols'\n",
    "if arch == 'AArch32':\n",
    "    xml_file = '../../test-generator/mra_tools/v8.6/ISA_AArch32_xml_v86A-2019-12'\n",
    "else:\n",
    "    xml_file =  '../../test-generator/mra_tools/v8.6/ISA_A64_xml_v86A-2019-12'\n",
    "\n",
    "# run the test case generator script\n",
    "script_to_run = '../../test-generator/genInsts.py'\n",
    "script_arguments = [\n",
    "    '--altslicesyntax', \n",
    "    '--demangle', \n",
    "    '--verbose', \n",
    "    '-o', '../../test-generator/mra_tools/arch/arch', \n",
    "    xml_file, \n",
    "    '--encoding', encoding, \n",
    "    '--arch', arch, \n",
    "    '--strategy', strategy\n",
    "]\n",
    "try:\n",
    "    if not os.path.exists(f\"{strategy}/{encoding}\"):\n",
    "       os.makedirs(f\"{strategy}/{encoding}\")\n",
    "    # Run the script using subprocess\n",
    "    for i in range(10):\n",
    "        subprocess.run(['python3', script_to_run] + script_arguments, check=True)\n",
    "        subprocess.run(['mv', f'{encoding}.txt', f'{strategy}/{encoding}/{encoding}_{i}.txt'], check=True)\n",
    "        subprocess.run(['mv', f'{encoding}_constraints.json', f'{strategy}/{encoding}/{encoding}_constraints_{i}.json'], check=True)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error running {script_to_run}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================A64===========================\n",
      "=============Instruction Stream================\n",
      "symbolic       = 1041355.4\n",
      "random         = 421645.4\n",
      "random_symbols = 573977.2\n",
      "=============Instruction Encoding================\n",
      "symbolic       = 837.0\n",
      "random         = 265.6\n",
      "random_symbols = 839.0\n",
      "=============Instruction================\n",
      "symbolic       = 579.0\n",
      "random         = 265.6\n",
      "random_symbols = 581.0\n",
      "=============Constraint================\n",
      "symbolic       = 3429.8\n",
      "random         = 934.8\n",
      "random_symbols = 3060.9\n",
      "==============================A64==========================\n",
      "\n",
      "==============================A32===========================\n",
      "=============Instruction Stream================\n",
      "symbolic       = 949704.6\n",
      "random         = 582849.7\n",
      "random_symbols = 641995.6\n",
      "=============Instruction Encoding================\n",
      "symbolic       = 550.0\n",
      "random         = 414.6\n",
      "random_symbols = 550.0\n",
      "=============Instruction================\n",
      "symbolic       = 481.0\n",
      "random         = 7.9\n",
      "random_symbols = 481.0\n",
      "=============Constraint================\n",
      "symbolic       = 5317.9\n",
      "random         = 3716.1\n",
      "random_symbols = 4935.3\n",
      "==============================A32==========================\n",
      "\n",
      "==============================T32===========================\n",
      "=============Instruction Stream================\n",
      "symbolic       = 873921.4\n",
      "random         = 34598.8\n",
      "random_symbols = 478143.2\n",
      "=============Instruction Encoding================\n",
      "symbolic       = 529.9\n",
      "random         = 351.5\n",
      "random_symbols = 531.0\n",
      "=============Instruction================\n",
      "symbolic       = 449.9\n",
      "random         = 9.1\n",
      "random_symbols = 451.0\n",
      "=============Constraint================\n",
      "symbolic       = 5008.0\n",
      "random         = 3203.2\n",
      "random_symbols = 4675.0\n",
      "==============================T32==========================\n",
      "\n",
      "==============================T16===========================\n",
      "=============Instruction Stream================\n",
      "symbolic       = 928.3\n",
      "random         = 796.6\n",
      "random_symbols = 890.1\n",
      "=============Instruction Encoding================\n",
      "symbolic       = 77.1\n",
      "random         = 57.2\n",
      "random_symbols = 78.0\n",
      "=============Instruction================\n",
      "symbolic       = 67.3\n",
      "random         = 2.2\n",
      "random_symbols = 68.0\n",
      "=============Constraint================\n",
      "symbolic       = 119.8\n",
      "random         = 84.1\n",
      "random_symbols = 107.1\n",
      "==============================T16==========================\n",
      "\n",
      "==============================Overall===========================\n",
      "symbolic       = {'number': 2865909.6999999997, 'cover_encoding': 1994.0, 'cover_instruction': 1577.2, 'cover_constraint': 13875.5}\n",
      "random         = {'number': 1039890.5, 'cover_encoding': 1088.9, 'cover_instruction': 284.8, 'cover_constraint': 7938.2}\n",
      "random_symbols = {'number': 1695006.0999999999, 'cover_encoding': 1998.0, 'cover_instruction': 1581.0, 'cover_constraint': 12778.300000000001}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "overall = {\n",
    "    'symbolic': {\n",
    "        \"number\": 0,\n",
    "        \"cover_encoding\": 0,\n",
    "        \"cover_instruction\": 0,\n",
    "        \"cover_constraint\": 0\n",
    "    },\n",
    "    'random': {\n",
    "        \"number\": 0,\n",
    "        \"cover_encoding\": 0,\n",
    "        \"cover_instruction\": 0,\n",
    "        \"cover_constraint\": 0\n",
    "    },\n",
    "    'random_symbols': {\n",
    "        \"number\": 0,\n",
    "        \"cover_encoding\": 0,\n",
    "        \"cover_instruction\": 0,\n",
    "        \"cover_constraint\": 0\n",
    "    }\n",
    "}\n",
    "\n",
    "def calculate_statistics(instspath, encoding):\n",
    "    results = {\n",
    "        \"number\": [],\n",
    "        \"cover_encoding\": [],\n",
    "        \"cover_instruction\": [],\n",
    "        \"cover_constraint\": []\n",
    "    }\n",
    "    for i in range(10):\n",
    "        valid_file = f\"{instspath}/{encoding}_{i}.txt\" \n",
    "        with open(valid_file,\"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            results[\"number\"].append(len(lines))\n",
    "        \n",
    "        valid_constraint_file = f\"{instspath}/{encoding}_constraints_{i}.json\"\n",
    "        tmp = set()\n",
    "        with open(valid_constraint_file,\"r\") as f:\n",
    "            constraint_file_data = json.load(f)\n",
    "            results[\"cover_encoding\"].append(len(constraint_file_data.keys()))\n",
    "            results[\"cover_constraint\"].append(str(constraint_file_data).count(\"True\"))\n",
    "            for k in constraint_file_data:\n",
    "                if encoding == 'A64':\n",
    "                    if '#' in k:\n",
    "                        tmp.add(k.split(\"#\")[1])\n",
    "                    else:\n",
    "                        tmp.add(k)\n",
    "                elif '#' in k:\n",
    "                    tmp.add(k.split(\"#\")[1])\n",
    "                else:\n",
    "                    tmp.add(k.split(\"/\")[-1])\n",
    "        results[\"cover_instruction\"].append(len(tmp))\n",
    "    return results\n",
    "\n",
    "def calculate_average(random, random_symbols, symbolic):\n",
    "    mapping = {\n",
    "        'number': 'Instruction Stream',\n",
    "        'cover_encoding': 'Instruction Encoding',\n",
    "        'cover_instruction': 'Instruction',\n",
    "        'cover_constraint': 'Constraint'\n",
    "    }\n",
    "    for item in ['number', 'cover_encoding', 'cover_instruction', 'cover_constraint']:\n",
    "        print(f\"============={mapping[item]}================\")\n",
    "        overall['symbolic'][item] += sum(symbolic[item])/len(symbolic[item])\n",
    "        overall['random'][item] += sum(random[item])/len(random[item])\n",
    "        overall['random_symbols'][item] += sum(random_symbols[item])/len(random_symbols[item])\n",
    "        print(f\"symbolic       = {sum(symbolic[item])/len(symbolic[item])}\")\n",
    "        print(f\"random         = {sum(random[item])/len(random[item])}\")\n",
    "        print(f\"random_symbols = {sum(random_symbols[item])/len(random_symbols[item])}\")\n",
    "    \n",
    "\n",
    "for encoding in ['A64', 'A32', 'T32', 'T16']:\n",
    "    print(f\"=============================={encoding}===========================\")\n",
    "    random = calculate_statistics(f\"random/{encoding}\", encoding)\n",
    "    random_symbols = calculate_statistics(f\"random-symbols/{encoding}\", encoding)\n",
    "    symbolic = calculate_statistics(f\"symbolic/{encoding}\", encoding)\n",
    "    calculate_average(random, random_symbols, symbolic)\n",
    "    print(f\"=============================={encoding}==========================\\n\")\n",
    "\n",
    "print(f\"==============================Overall===========================\")\n",
    "print(f\"symbolic       = {overall['symbolic']}\")\n",
    "print(f\"random         = {overall['random']}\")\n",
    "print(f\"random_symbols = {overall['random_symbols']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========A32===========\n",
      "========T32===========\n",
      "========T16===========\n",
      "instruction encoding: 100.0, 0.00016399116127605647\n",
      "instruction encoding: (1.0, 'large')\n",
      "instruction: 100.0, 0.00014417610153880437\n",
      "instruction: (1.0, 'large')\n",
      "constraint: 100.0, 0.00014589964277689183\n",
      "constraint: (1.0, 'large')\n",
      "================\n",
      "instruction encoding: 0.0, 5.5941681768311536e-05\n",
      "instruction encoding: (-1.0, 'large')\n",
      "instruction: 0.0, 4.7682291610117017e-05\n",
      "instruction: (-1.0, 'large')\n",
      "constraint: 100.0, 0.00014589964277689183\n",
      "constraint: (1.0, 'large')\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "from cliffs_delta import cliffs_delta\n",
    "\n",
    "def element_wise_sum(d1, d2):\n",
    "    new_dict = {}\n",
    "    for key in d1.keys():\n",
    "        new_dict[key] = [x + y for x, y in zip(d1[key], d2[key])]\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "def utest(a, b):\n",
    "    # Perform Mann-Whitney U test\n",
    "    statistic, p_value= mannwhitneyu(a['cover_encoding'], b['cover_encoding'])\n",
    "    result =  cliffs_delta(a['cover_encoding'], b['cover_encoding'])\n",
    "    print(f\"instruction encoding: {statistic}, {p_value}\")\n",
    "    print(f\"instruction encoding: {result}\")\n",
    "    statistic, p_value = mannwhitneyu(a['cover_instruction'], b['cover_instruction'])\n",
    "    result =  cliffs_delta(a['cover_instruction'], b['cover_instruction'])\n",
    "    print(f\"instruction: {statistic}, {p_value}\")\n",
    "    print(f\"instruction: {result}\")\n",
    "    statistic, p_value = mannwhitneyu(a['cover_constraint'], b['cover_constraint'])\n",
    "    result =  cliffs_delta(a['cover_constraint'], b['cover_constraint'])\n",
    "    print(f\"constraint: {statistic}, {p_value}\")\n",
    "    print(f\"constraint: {result}\")\n",
    "\n",
    "encoding = 'A64'\n",
    "random = calculate_statistics(f\"random/{encoding}\", encoding)\n",
    "random_symbols = calculate_statistics(f\"random-symbols/{encoding}\", encoding)\n",
    "symbolic = calculate_statistics(f\"symbolic/{encoding}\", encoding)\n",
    "# print(random)\n",
    "\n",
    "for encoding in ['A32', 'T32', 'T16']:\n",
    "    print(f\"========{encoding}===========\")\n",
    "    random_temp = calculate_statistics(f\"random/{encoding}\", encoding)\n",
    "    random_symbols_temp = calculate_statistics(f\"random-symbols/{encoding}\", encoding)\n",
    "    symbolic_temp = calculate_statistics(f\"symbolic/{encoding}\", encoding)\n",
    "    random = element_wise_sum(random, random_temp)\n",
    "    random_symbols = element_wise_sum(random_symbols, random_symbols_temp)\n",
    "    symbolic = element_wise_sum(symbolic, symbolic_temp)\n",
    "    # print(random)\n",
    "    # print(random_symbols)\n",
    "    # print(symbolic)\n",
    "\n",
    "utest(symbolic, random)\n",
    "print(\"=\"*16)\n",
    "utest(symbolic, random_symbols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========A64===========\n",
      "{'number': [1075285, 1035510, 1035218, 1034993, 1036878, 1036787, 1035648, 1036446, 1036410, 1035730], 'cover_encoding': [1085, 1087, 1091, 1084, 1089, 1092, 1088, 1085, 1093, 1095], 'cover_instruction': [289, 284, 282, 280, 287, 286, 280, 281, 287, 292], 'cover_constraint': [7926, 7876, 7937, 7935, 7893, 7976, 7979, 7939, 7959, 7962]}\n",
      "{'number': [1692410, 1696858, 1694415, 1697284, 1699049, 1688311, 1691975, 1690422, 1697624, 1701713], 'cover_encoding': [1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998], 'cover_instruction': [1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581], 'cover_constraint': [12771, 12767, 12791, 12778, 12793, 12753, 12784, 12773, 12790, 12783]}\n",
      "{'number': [2885423, 2840984, 2849953, 2877776, 2845922, 2863218, 2844942, 2902523, 2898515, 2849841], 'cover_encoding': [1994, 1995, 1995, 1994, 1995, 1994, 1993, 1994, 1993, 1993], 'cover_instruction': [1577, 1578, 1578, 1577, 1578, 1577, 1577, 1577, 1576, 1577], 'cover_constraint': [13876, 13876, 13876, 13875, 13876, 13876, 13875, 13875, 13876, 13874]}\n",
      "instruction encoding: 100.0, 0.00016399116127605647\n",
      "instruction encoding: (1.0, 'large')\n",
      "instruction: 100.0, 0.00014417610153880437\n",
      "instruction: (1.0, 'large')\n",
      "constraint: 100.0, 0.00014589964277689183\n",
      "constraint: (1.0, 'large')\n",
      "================\n",
      "instruction encoding: 0.0, 5.5941681768311536e-05\n",
      "instruction encoding: (-1.0, 'large')\n",
      "instruction: 0.0, 4.7682291610117017e-05\n",
      "instruction: (-1.0, 'large')\n",
      "constraint: 100.0, 0.00014589964277689183\n",
      "constraint: (1.0, 'large')\n",
      "========A32===========\n",
      "{'number': [1075285, 1035510, 1035218, 1034993, 1036878, 1036787, 1035648, 1036446, 1036410, 1035730], 'cover_encoding': [1085, 1087, 1091, 1084, 1089, 1092, 1088, 1085, 1093, 1095], 'cover_instruction': [289, 284, 282, 280, 287, 286, 280, 281, 287, 292], 'cover_constraint': [7926, 7876, 7937, 7935, 7893, 7976, 7979, 7939, 7959, 7962]}\n",
      "{'number': [1692410, 1696858, 1694415, 1697284, 1699049, 1688311, 1691975, 1690422, 1697624, 1701713], 'cover_encoding': [1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998], 'cover_instruction': [1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581], 'cover_constraint': [12771, 12767, 12791, 12778, 12793, 12753, 12784, 12773, 12790, 12783]}\n",
      "{'number': [2885423, 2840984, 2849953, 2877776, 2845922, 2863218, 2844942, 2902523, 2898515, 2849841], 'cover_encoding': [1994, 1995, 1995, 1994, 1995, 1994, 1993, 1994, 1993, 1993], 'cover_instruction': [1577, 1578, 1578, 1577, 1578, 1577, 1577, 1577, 1576, 1577], 'cover_constraint': [13876, 13876, 13876, 13875, 13876, 13876, 13875, 13875, 13876, 13874]}\n",
      "instruction encoding: 100.0, 0.00016399116127605647\n",
      "instruction encoding: (1.0, 'large')\n",
      "instruction: 100.0, 0.00014417610153880437\n",
      "instruction: (1.0, 'large')\n",
      "constraint: 100.0, 0.00014589964277689183\n",
      "constraint: (1.0, 'large')\n",
      "================\n",
      "instruction encoding: 0.0, 5.5941681768311536e-05\n",
      "instruction encoding: (-1.0, 'large')\n",
      "instruction: 0.0, 4.7682291610117017e-05\n",
      "instruction: (-1.0, 'large')\n",
      "constraint: 100.0, 0.00014589964277689183\n",
      "constraint: (1.0, 'large')\n",
      "========T32===========\n",
      "{'number': [1075285, 1035510, 1035218, 1034993, 1036878, 1036787, 1035648, 1036446, 1036410, 1035730], 'cover_encoding': [1085, 1087, 1091, 1084, 1089, 1092, 1088, 1085, 1093, 1095], 'cover_instruction': [289, 284, 282, 280, 287, 286, 280, 281, 287, 292], 'cover_constraint': [7926, 7876, 7937, 7935, 7893, 7976, 7979, 7939, 7959, 7962]}\n",
      "{'number': [1692410, 1696858, 1694415, 1697284, 1699049, 1688311, 1691975, 1690422, 1697624, 1701713], 'cover_encoding': [1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998], 'cover_instruction': [1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581], 'cover_constraint': [12771, 12767, 12791, 12778, 12793, 12753, 12784, 12773, 12790, 12783]}\n",
      "{'number': [2885423, 2840984, 2849953, 2877776, 2845922, 2863218, 2844942, 2902523, 2898515, 2849841], 'cover_encoding': [1994, 1995, 1995, 1994, 1995, 1994, 1993, 1994, 1993, 1993], 'cover_instruction': [1577, 1578, 1578, 1577, 1578, 1577, 1577, 1577, 1576, 1577], 'cover_constraint': [13876, 13876, 13876, 13875, 13876, 13876, 13875, 13875, 13876, 13874]}\n",
      "instruction encoding: 100.0, 0.00016399116127605647\n",
      "instruction encoding: (1.0, 'large')\n",
      "instruction: 100.0, 0.00014417610153880437\n",
      "instruction: (1.0, 'large')\n",
      "constraint: 100.0, 0.00014589964277689183\n",
      "constraint: (1.0, 'large')\n",
      "================\n",
      "instruction encoding: 0.0, 5.5941681768311536e-05\n",
      "instruction encoding: (-1.0, 'large')\n",
      "instruction: 0.0, 4.7682291610117017e-05\n",
      "instruction: (-1.0, 'large')\n",
      "constraint: 100.0, 0.00014589964277689183\n",
      "constraint: (1.0, 'large')\n",
      "========T16===========\n",
      "{'number': [1075285, 1035510, 1035218, 1034993, 1036878, 1036787, 1035648, 1036446, 1036410, 1035730], 'cover_encoding': [1085, 1087, 1091, 1084, 1089, 1092, 1088, 1085, 1093, 1095], 'cover_instruction': [289, 284, 282, 280, 287, 286, 280, 281, 287, 292], 'cover_constraint': [7926, 7876, 7937, 7935, 7893, 7976, 7979, 7939, 7959, 7962]}\n",
      "{'number': [1692410, 1696858, 1694415, 1697284, 1699049, 1688311, 1691975, 1690422, 1697624, 1701713], 'cover_encoding': [1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998, 1998], 'cover_instruction': [1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581, 1581], 'cover_constraint': [12771, 12767, 12791, 12778, 12793, 12753, 12784, 12773, 12790, 12783]}\n",
      "{'number': [2885423, 2840984, 2849953, 2877776, 2845922, 2863218, 2844942, 2902523, 2898515, 2849841], 'cover_encoding': [1994, 1995, 1995, 1994, 1995, 1994, 1993, 1994, 1993, 1993], 'cover_instruction': [1577, 1578, 1578, 1577, 1578, 1577, 1577, 1577, 1576, 1577], 'cover_constraint': [13876, 13876, 13876, 13875, 13876, 13876, 13875, 13875, 13876, 13874]}\n",
      "instruction encoding: 100.0, 0.00016399116127605647\n",
      "instruction encoding: (1.0, 'large')\n",
      "instruction: 100.0, 0.00014417610153880437\n",
      "instruction: (1.0, 'large')\n",
      "constraint: 100.0, 0.00014589964277689183\n",
      "constraint: (1.0, 'large')\n",
      "================\n",
      "instruction encoding: 0.0, 5.5941681768311536e-05\n",
      "instruction encoding: (-1.0, 'large')\n",
      "instruction: 0.0, 4.7682291610117017e-05\n",
      "instruction: (-1.0, 'large')\n",
      "constraint: 100.0, 0.00014589964277689183\n",
      "constraint: (1.0, 'large')\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "from cliffs_delta import cliffs_delta\n",
    "\n",
    "\n",
    "\n",
    "def utest(a, b):\n",
    "    # Perform Mann-Whitney U test\n",
    "    statistic, p_value= mannwhitneyu(a['cover_encoding'], b['cover_encoding'])\n",
    "    result =  cliffs_delta(a['cover_encoding'], b['cover_encoding'])\n",
    "    print(f\"instruction encoding: {statistic}, {p_value}\")\n",
    "    print(f\"instruction encoding: {result}\")\n",
    "    statistic, p_value = mannwhitneyu(a['cover_instruction'], b['cover_instruction'])\n",
    "    result =  cliffs_delta(a['cover_instruction'], b['cover_instruction'])\n",
    "    print(f\"instruction: {statistic}, {p_value}\")\n",
    "    print(f\"instruction: {result}\")\n",
    "    statistic, p_value = mannwhitneyu(a['cover_constraint'], b['cover_constraint'])\n",
    "    result =  cliffs_delta(a['cover_constraint'], b['cover_constraint'])\n",
    "    print(f\"constraint: {statistic}, {p_value}\")\n",
    "    print(f\"constraint: {result}\")\n",
    "\n",
    "\n",
    "for encoding in ['A64', 'A32', 'T32', 'T16']:\n",
    "    print(f\"========{encoding}===========\")\n",
    "    random_temp = calculate_statistics(f\"random/{encoding}\", encoding)\n",
    "    random_symbols_temp = calculate_statistics(f\"random-symbols/{encoding}\", encoding)\n",
    "    symbolic_temp = calculate_statistics(f\"symbolic/{encoding}\", encoding)\n",
    "    \n",
    "    print(random)\n",
    "    print(random_symbols)\n",
    "    print(symbolic)\n",
    "    utest(symbolic, random)\n",
    "    print(\"=\"*16)\n",
    "    utest(symbolic, random_symbols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
