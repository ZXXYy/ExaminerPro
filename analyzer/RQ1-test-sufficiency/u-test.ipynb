{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate test cases 10 times using different strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "\n",
    "encoding = 'A32'\n",
    "arch = 'AArch32'\n",
    "strategy = 'random-symbols'\n",
    "if arch == 'AArch32':\n",
    "    xml_file = '../../test-generator/mra_tools/v8.6/ISA_AArch32_xml_v86A-2019-12'\n",
    "else:\n",
    "    xml_file =  '../../test-generator/mra_tools/v8.6/ISA_A64_xml_v86A-2019-12'\n",
    "\n",
    "# run the test case generator script\n",
    "script_to_run = '../../test-generator/genInsts.py'\n",
    "script_arguments = [\n",
    "    '--altslicesyntax', \n",
    "    '--demangle', \n",
    "    '--verbose', \n",
    "    '-o', '../../test-generator/mra_tools/arch/arch', \n",
    "    xml_file, \n",
    "    '--encoding', encoding, \n",
    "    '--arch', arch, \n",
    "    '--strategy', strategy\n",
    "]\n",
    "try:\n",
    "    if not os.path.exists(f\"{strategy}/{encoding}\"):\n",
    "       os.makedirs(f\"{strategy}/{encoding}\")\n",
    "    # Run the script using subprocess\n",
    "    for i in range(10):\n",
    "        subprocess.run(['python3', script_to_run] + script_arguments, check=True)\n",
    "        subprocess.run(['mv', f'{encoding}.txt', f'{strategy}/{encoding}/{encoding}_{i}.txt'], check=True)\n",
    "        subprocess.run(['mv', f'{encoding}_constraints.json', f'{strategy}/{encoding}/{encoding}_constraints_{i}.json'], check=True)\n",
    "\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Error running {script_to_run}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'number': [886], 'cover_encoding': [78], 'cover_instruction': [68], 'cover_constraint': [107]}\n",
      "{'number': [925], 'cover_encoding': [76], 'cover_instruction': [67], 'cover_constraint': [119]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "encoding = 'T16'\n",
    "\n",
    "def calculate_statistics(instspath, encoding):\n",
    "    results = {\n",
    "        \"number\": [],\n",
    "        \"cover_encoding\": [],\n",
    "        \"cover_instruction\": [],\n",
    "        \"cover_constraint\": []\n",
    "    }\n",
    "    for i in range(1):\n",
    "        valid_file = f\"{instspath}/{encoding}_{i}.txt\"\n",
    "        with open(valid_file,\"r\") as f:\n",
    "            lines = f.readlines()\n",
    "            results[\"number\"].append(len(lines))\n",
    "        \n",
    "        valid_constraint_file = f\"{instspath}/{encoding}_constraints_{i}.json\"\n",
    "        tmp = set()\n",
    "        with open(valid_constraint_file,\"r\") as f:\n",
    "            constraint_file_data = json.load(f)\n",
    "            results[\"cover_encoding\"].append(len(constraint_file_data.keys()))\n",
    "            results[\"cover_constraint\"].append(str(constraint_file_data).count(\"True\"))\n",
    "            for k in constraint_file_data:\n",
    "                tmp.add(k.split(\"#\")[1])\n",
    "        results[\"cover_instruction\"].append(len(tmp))\n",
    "    return results\n",
    "\n",
    "\n",
    "# random = calculate_statistics(f\"random/{encoding}\", encoding)\n",
    "random_symbols = calculate_statistics(f\"random-symbols/{encoding}\", encoding)\n",
    "symbolic = calculate_statistics(f\"symbolic/{encoding}\", encoding)\n",
    "\n",
    "# print(random)\n",
    "print(random_symbols)\n",
    "print(symbolic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1.0, 'large')\n",
      "100.0 6.113336892015162e-05\n",
      "(-1.0, 'large')\n",
      "100.0 0.00012855089812896465\n",
      "(1.0, 'large')\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import mannwhitneyu\n",
    "from cliffs_delta import cliffs_delta\n",
    "def compute_vda(statistic, n1, n2):\n",
    "    return (2 * statistic) / (n1 * n2) - (n1 + n2 + 1) / (n1 * n2)\n",
    "\n",
    "# Perform Mann-Whitney U test\n",
    "statistic, p_value= mannwhitneyu(symbolic['cover_encoding'], random['cover_encoding'])\n",
    "result =  cliffs_delta(symbolic['cover_encoding'], random['cover_encoding'])\n",
    "print(result)\n",
    "statistic, p_value = mannwhitneyu(symbolic['cover_instruction'], random['cover_instruction'])\n",
    "result =  cliffs_delta(symbolic['cover_instruction'], random['cover_instruction'])\n",
    "print(statistic, p_value)\n",
    "print(result)\n",
    "statistic, p_value = mannwhitneyu(symbolic['cover_constraint'], random['cover_constraint'])\n",
    "result =  cliffs_delta(symbolic['cover_constraint'], random['cover_constraint'])\n",
    "print(statistic, p_value)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
